inventionsMDPIArticleA Fingerprint Matching Algorithm Using the Combination of The Modelling & Simulation Laboratory, Dunarea de Jos University of Galati, 47 Domneasca Str.800008 Galati, Romania; andreea.dinca@ugal.ro (A.-M.D.L.); simona.moldovanu@ugal.ro (S.M.)Mihail Kogalniceanu High School, 161B Brailei St., 800320 Galati, RomaniaDepartment of Computer Science and Information Technology, Faculty of Automation, Computers,800008 Galati, RomaniaUniversity of Galati, 47 Domneasca Str., 800008 Galati, RomaniaCorrespondence: luminita.moraru@ugal.roAbstract: This study presents an algorithm for fingerprint classification using a CNN (convolutionalneural network) model and making use of full images belonging to four digital databases. The mainchallenge that we face in fingerprint classification is dealing with the low quality of fingerprintswhich can impede the identification process. To overcome these restrictions, the proposed modelPrimarily, the fingerprint images are enhanced using Prewitt and Laplacian of Gaussian filters. Thischeck forinvestigation used the fingerprint verification competition with four databases (FVC2004, DB1, DB2)updatesDB3, and DB4) which contain 240 real fingerprint images and 80 synthetic fingerprint images. TheCitation: Dinca Lazarescu, A.-M.real images were collected using various sensors. The innovation of the model is in the manner inMoldovanu, S.; Moraru, L. Anumber of epochs is defined as a hyper-parameter which can influence the performance of the deepUsing the Combination of Edgelearning model. The number of epochs was set to 10, 20, 30, and 50 in order to keep the training timeFeatures and Convolution Neural at an acceptable value of 1.8 s/epoch, on average. Our results indicate the overfitting of the modelNetworks. Inventions 2022, 7, 39.https:/ /doi.org/10.3390/ starting with the seventh epoch. The accuracy varies from 67.6% to 98.7% for the validation set, andbetween 70.2% and 75.6% for the test set. The proposed method achieved a very good performance inventions7020039 compared to the traditional hand-crafted features despite the fact that it used raw data and it doesAcademic Editor: Anastasiosnot perform any handcrafted feature extraction operations. DoulamisReceived: 10 May 2022Keywords: convolutional neural networks; fingerprint images; data augmentation; fingerprintAccepted: 26 May 2022classificationPublished: 27 May 2022 Publisher's Note: MDPI stays neutralwith regard to jurisdictional claims in1. Introduction published maps and institutional affil-iations.Various approaches to automatically authenticate fingerprints for personal identifica-tion and verification have found important applications in ensuring public security andcriminal investigations. A fingerprint represents a graphical pattern on the surface of ahuman finger expressed by ridges and valleys. Ridges are the upper skin surface parts ofCopyright: @ 2022 by the authors. the finger that touch a surface, and valleys are the lower parts. In a fingerprint image, ridgeLicensee MDPI, Basel, Switzerland.lines are the dark areas, and valleys are the bright areas which represent the inter-ridgeThis article is an open access articlespaces. Fingerprints are unique and are the most reliable human feature which can bedistributed under the terms andutilized for personal identification  I.conditions of the Creative CommonsAutomatic fingerprint identification uses fingerprint features such as ridge flow, ridgeAttribution (CC BY) license (https:/ /period, ridge ending, and the delta or core points for fingerprint enrollment and verificationcreativecommons.org/licenses /by /steps [ I. Matching performance is strongly affected by fingertip surface conditions such4.0/)Inventions 2022, 7, 39. https: / /doi.org/10.3390/inventions7020039https:/ /www.mdpi.com/journal /inventionsInventions 2022, 7, 392 of 13as fingerprint deformations or distortions, fingerprint collection conditions, variationsin the pressure between the finger and the acquisition sensor, scars, age, race, sex, etc.Additionally, the minutiae extraction can be affected by noise, rotation, and the scaleof the images or fingerprint alignment information [ - J. There is a sinusoidal-shapedwave of ridges with some slow changes in their orientation. This characteristic defines afingerprint pattern. However, fingerprint images are prone to structural imperfections. Inorder to create an accurate identification system, an effective enhancement algorithm isnecessary. This algorithm can be coupled with a performance classification method  , I. Amajor limitation of fingerprint recognition algorithms is that only small-area fingerprintimages are usually available to the algorithm for differential matching. This calls fora model which can solve the restoration of the whole fingerprint image to make thel. The enhancementstep is based on the obvious directional behavior manifested in a fingerprint image. Someeffective enhancement technigues are based on the Prewitt and Laplacian of Gaussianfilters t Additionally, a robust feature extractor and classifier must be able to deal with augmentation operations such as translation, rotation, or skin distortion.The process of feature extraction and matching demands some preprocessing opera-tions such as ridge enhancement (for a fingerprint structure clarity), followed by featurebeen heavily used in image recognition. Most of these are devoted to a single-framerecognition with an improved classification performance Ll. The main advantage ofCNN-based classifiers is that they are fully independent of any human actions devotedto feature extraction and classification. For large databases, the computational cost ofsearching for a fingerprint image is huge, but CNNs drastically reduce this burden.In the present study, starting from the fact that the existing fingerprint recognitionalgorithms rely too heavily on the details of the fingerprint, a software solution wasproposed to evaluate the quality of fingerprint identification by using a convolutionalneural network (CNN) architecture and by calling full images belonging to four digitaldatabases. We did not perform any handcrafted feature extraction operations. The mainchallenge that we face is the low quality of fingerprints, which can impede or make theidentification process difficult.The main contributions of this work are as follows:Despite intense development efforts, there is still one open research problem devotedto the restoration of whole fingerprint images to make the process of fingerprintrecognition and matching more effective. We discuss the investigation of wholefingerprint imagesWe aim to validate the edge enhancement operations, data augmentation, and thenetwork structure regarding the potential of a CNN architecture to accurately identifythe fingerprints for a further classification taskThe Prewitt and Laplacian of Gaussian filters are used to enhance the edges that separatethe ridges and valleys in the fingerprint images. Moreover, we do not use any skeletoniza-tion operations to convert gray-scale fingerprint images to black-and-white images.To decrease the training time, we reduce the dimensionality of the fingerprint imagesfrom [256 × 256] to [80 × 80] pixels.To improve the performance of the proposed model, we use the rotation as a dataaugmentation technique.As CNNs can learn discriminative features from whole fingerprint images and theydo not require explicit feature extraction to do so, the deep learning approach is anattractive option in fingerprint identification. Thus, the performance of the proposedCNN model is evaluated based on the accuracies for the training and validation testswith attention paid to the number of epochs, which is considered the hyper-parameterThe rest of this paper is organized as follows: Section reviews the related litera-ture and emphasizes the most important sources of our motivation. Also, in SectionInventions 2022, 7, 393 of 13the adopted methodology, the design of our CNN method, and the used databases arepresented. Section shows the results obtained from several experiments, discusses andevaluates the accuracy values provided by the individual systems. Finally, Sectionprovides a summary of our research and sets out our future work intentions.2. Materials and Methods2.1. Related Work Over the last thirty years, there have been important developments in deep learningmethods. These developments had a significant impact on a wide range of applicationsdealing with computer vision and pattern recognition. The research field of automaticfingerprint recognition is among the most interesting topics, due to the requirement toincrease the recognition accuracy rate. Additionally, deep learning methods avoid the focuson methods devoted to minutiae extraction as handcrafted features, shifting the interest tothe analysis of the whole image. The latest investigations devoted to the field of fingerprintimage organization are reviewed in this sectionThe most sensitive step in the fingerprint recognition scheme is image improvement.Wang et al. [I proposed an algorithm for fingerprint image quality enhancement, i.e.,to improve the clarity and continuity of ridges, based on the wavelet transform and amechanism of compensation coefficients for each sub-band based on a Gaussian template.Yang et al. L I presented an enhancement technique which approached both spatial andfrequency domains. A spatial ridge-compensation filter was employed to enhance thefingerprint image in the spatial domain. Then, a frequency bandpass filter performed sharpattenuation of both the radial and angular-frequency domains. Shrein et al. [J used aconvolutional neural network that performed the classification tasks for fingerprints inthe IAFIS (integrated automated fingerprint identification system) database with 95.9%accuracy. He has shown that precise image preprocessing, aiming to reduce the dimen-moderate depth. Mohamed [I thoroughly investigated all the factors which may affect stage dealing with increasing the fingerprint quality, and a post-processing step devoted totraining and classification. A resized image (its dimensions reduced from 512 × 512 pixelsto 200 × 200 pixels) was created in order to reduce the training time.. A classificationJ used a pre-trained convolutional neural network and two fingerprint databases with heterogeneouscharacteristics (PolyU and NIST) for classification purposes. The used features were thearch, left loop, right loop, whorl, and three nets: AlexNet, GoogLeNet, and ResNet. The comparative analysis allowed the system to determine the type of classification that shouldbe used for the best performance in terms of precision and model efficiency. Borra et al. freported a method based on a denoising procedure (the wave atom transform technique)image augmentation (based on morphological operations), and an adaptive genetic neuralnetwork in order to evaluate the performance of the approach. The networks used thefeature values that were extracted from each image.The experiments were performedon the FVC2000 databases. The authors reported better performance values comparedto some neural networks and machine learning approaches. Listyalina et al. [I soughtto classify raw fingerprint images. They proposed a deep learning method (i.e., transferlearning GoogLeNet) which transferred the classification steps, such as pre-processing,feature extraction, and classification rather than training a deep CNN architecture. Theyused fingerprint images from the NiST-4 database and reported performance accuracy mea- sures as follows: 94.7% and 96.2% for the five-class and four-class classification problemsrespectively. Tertychnyi et al. [I proposed an efficient deep neural network algorithm to recognize low-quality fingerprint images. These images are affected by physical damage,dryness, wetness, and/or blurriness. A VGG16 convolutional network model was em-ployed based on transfer learning for training. In addition, both image dimension reductionand data augmentation were performed to improve the computing cost. They reported anInventions 2022, 7, 394 of 13 average accuracy of 89.4%; this is almost the same accuracy provided by regular CNNs.Finally, Pandya et al. [ I proposed a model which encompasses a pre-processing stage(histogram equalization, enhancement based on a Gabor filter, and ridge thinning) and aclassification stage using a CNN architecture. The proposed algorithm achieved a 98.21%classification accuracy with a 0.9 loss for 560 samples (56 users providing 10 images each).Overfitting was avoided by Nur-A-Alam et al. [ I using a combination of the Gabor filter-ing technique coupled with deep learning techniques and principal component analysis(PCA). The meaningful features that can support an automatic authentication process forthe fingerprint for personal identification and verification were extracted using the fusionof CNNs and Gabor filters; PCA reduces the dimensionality of statistical features. Theproposed approach reached an accuracy of 99.87%. An efficient unimodal and multimodalbiometric system based on CNNs and feature selection for fast palmprint recognition wasrecently proposed by Trabelsi et al. [ ]. Simplified Gabor-PCA convolutional networks, an enhanced feature selection method, and a “reduction of the dimensions" approach wereused to achieve a high recognition rate, i.e., 0% equal error rate (meaning the best trade-offbetween false rejections and false acceptances) and 100% rank-one recognition (meaningthe percentage of samples recognized by the system). Oleiwi et al. I I introduced a finger-print classification method based on gender techniques, which integrates the Wiener filterfingerprint features followed by Softmax as a classifier.2.2. Proposed Methodology2.2.1. Mathematical ApproachesTo improve the quality of fingerprint images, the first- and second-order derivativefilters were used. An image is defined by an image function A(x, y) that gives the intensityof the gray levels at pixel position (x, y). The gradient vector of the image function isdefined as in IVA(x,y) =GxGy(1)dxdyPrewitt OperatorThe Prewitt filter detects the vertical and horizontal directions of the edges of an imageby locating those pixel values defined by steep gray values [I. The Prewitt operatorconsists of two 3 × 3 convolution masks [0* A(x,y)(2)Gy-100* A(x,y)(3)Gxwhere A is the image source and * is the 2D convolution operation.The Laplacian operatorThe Laplace operator is computed using the second-order derivative approximationsof the image function A(x, y). It is noise sensitive, so it is often combined with a Gaussianfilter to decrease the sensitivity to noise fI. The Laplacian filter searches the zero crossingpoints of the second-order derivatives of the image function and establishes the rapidchanges in adjacent pixel values that belong to an edge [. 22 A(x, y)22 A(x, y)2 A(x,y)(4)ax2dy2Inventions 2022, 7, 395 of 13A zero value indicates the areas of constant intensity, while values < O or > O are placedin the vicinity of an edge.The Laplacian of Gaussian (LoG) operatorFor an image A(x, y) with pixel intensity values (x, y), a combination of the Laplacian and Gaussian functions generates a new operator LoG [I, centered on zero and with aGaussian standard deviation o:x2+y2LoG(x,y) =2g2(5)2g2元04The Gaussian operator suppresses the noise before using the Laplace operator for edgedetection. The LoG operator detects areas where the intensity changes rapidly, namely thefunction's values are positive on the darker side (pixel values close to O) and negative onthe brighter side (pixel values close to 255) [2.2.2. DatasetThe analyzed fingerprint images belong to the FVC2004 database, which is the propertyof the University of Bologna, Italy I  I. The image data are described, in detail, in TableTable 1. Dataset characteristics.Total Image NumberFVC2004 DatasetsFingerprint ScannerImage SizeFingerprint Imagesafter AugmentationOptical sensor "V300"BD1640 × 48080720by CrossMatchBD2Optical sensor "U.are.U 4000"328 × 364104936Thermal Sweeping SensorBD3300 × 480104936BD4Synthetic fingerprint generator288 × 384104936In order to enhance the limitations of low-quality fingerprint images, both the Prewittand LoG filters were used to enhance the edges that separate the ridges and valleys in thel. Figure displays examples of image enhancement from eachused database and filter.2.2.3. Data AugmentationThe optimization of a CNN which uses small datasets means avoiding the networkthe training dataset and to prevent the issue of overfitting during training. The number ofimages has been increased nine times. Data augmentation has been performed by executing±30° rotations, from 0° to 360°. This provided a total of 3528 images, of which 2469 wereused as training samples. Additionally, each image was resized from 256 × 256 pixels to80 x 80 pixels to be more suitable to be fed into the network and to reduce the trainingtime. Figure shows an example of data augmentation.2.2.4. Convolutional Neural Networkpooling, and fully connected layers [J. CNNs perform well in recognition of imagestasks. To optimize the performance of a CNN model, it has to be trained to extract the mostimportant deep discriminatory features. As a general description of a CNN architecture and its learning strategy, we could mention that a gradual training process designed togiven image. Furthermore, from layer to layer the convolution filters are trained to detect more and more complex patterns, such as object features (Figure ). The model architectureInventions 2022, 7, 396 of 13is given in Table . The parameter settings and some hyperparameters selected for theAn epoch means the whole dataset passes once forward and backward through the neuralnetwork. Usually, the number of epochs is determined when the validation accuracy starts decreasing, even if the training accuracy is still increasing. In addition, one epoch is too large to be run through the model as a whole, so it is divided into several smaller subsamples called batches. A higher number of epochs increases the cost of computationalcomplexity and the risk of overfitting, respectively. The variation in the number of epochsstops when the validation loss no longer improves.BD1BD2BD3BD4images. Columns: left-raw grayscale images; middleedge enhancement using the Prewitt filter;right-edge enhancement using the LoG filter.Inventions 2022, 7, 397 of 13Out putDropout3Figure 3. CNN model architecture.Table 2. Model architecture and parameter settings.Output ShapeParamLayer (Type)sequential_11 (Sequential)(None, 80, 80, 3)0rescaling_7 (Rescaling)(None, 80, 80, 3)0conv2d_27 (Conv2D)(None, 80, 0, 8)224max_pooling2d_27 (MaxPooling2D)(None, 40, 40, 8)0conv2d_28 (Conv2D)(None, 40, 40, 16)1168max_pooling2d_28 (MaxPooling2D)(None, 20, 20, 16)0conv2d_29 (Conv2D)(None, 20, 20, 32)4640max_pooling2d_29 (MaxPooling2D)(None, 10, 10, 32)018,496conv2d_30 (Conv2D)(None, 10, 10, 64)max_pooling2d_30 (MaxPooling2D)(None, 5, 5, 64)0dropout_7 (Dropout)(None, 5, 5, 64)0flatten_7 (Flatten)0(None, 1600)204,928dense_14 (Dense)(None, 128)dense_15 (Dense)(None, 3)387expected so that the model is able to process batches of any sizeInventions 2022, 7, 398 of 13Table 3. The hyper-parameters of the CNN model.Hyper-ParametersName/DimensionEpochs10, 20, 30, 50Batch size20ReLUActivation functionImage size80 × 80Time consuming/20 epochs23 sLearning rate0.01The convolutional layers extract features from the input images. The size of the inputand their basic task is to reduce the feature dimensions or to reduce the feature map sizeby using the ReLU (rectified linear unit) activation function. The ReLU function doesnot activate all the neurons at the same time. If the output of the linear transformationis negative, the neurons are deactivated. The fully connected or dense layers exploit thelearned high-level features and act as classifiers. Additionally, to reduce overfitting andby augmentation. To evaluate the performance of the proposed method, the accuracy offingerprint identification is calculated [  I.3. Results and DiscussionThe experiment was carried out in MATLAB R2018a (The MathWorks, Natick, MAUSA), using the proposed approach and the image processing toolbox. The CNN wasimplemented using Python Jupyter Notebook) and the open-source platform Keras for theTensorFlow machine learning toolbox. It is run in Google Colaboratory (Colab)The image datasets were stored in Google Drive and the workspaces were connected.Of the total dataset, 60%, 20%, and 20% were used as the training set, validation set, and testset, respectively. The performance of the CNN model training and validation classificationaccuracy rate over the 10, 20, 30, and 50 epochs are shown in Figures - .. The classificationaccuracy is defined as the ratio between the correct predictions and the total number ofpredictions in the training or validation data., during the training of the CNN, the accuracy of the train-As shown in Figuresing set (blue line) continued to increase and the network was learning constantly. Thevalidation set (orange line) first increased, then overfitting occurred and the accuracyshowed an unstable variation. The same behavior was observed for loss curves. Conse-quently, we investigated the number of epochs and selected the best number to solve theoverfitting problem.The number of epochs was set to 10, 20, 30, and 50 in order to keep the training time at an acceptable value of 1.8 s /epoch, on average. Prior to each training epoch, the trainingdata was randomly shuffled. The performance of the proposed model is summarized inTable .Inventions 2022, 7, 399 of 13Training and Validation Accuracyand ValteFigure 4. Illustration of model accuracy rate for 50, 30, 20, and 10 epochs for DB1 dataset acquiredusing an optical sensor “V300" by CrossMatch.Training and Validation LossTraining and Validation AccuracyangeFigure 5. Ilustration of model accuracy rate for 50, 30, 20, and 10 epochs for DB2 dataset acquiredusing an optical sensor "U.are.U 4000".Inventions 2022, 7, 3910 of 13Training and Validation Lon AccuracyFigure 6. Illustration of model accuracy rate for 50, 30, 20, and 10 epochs for DB3 dataset acquiredusing a thermal sweeping sensor “FingerChip FCD4B14CB" by AtmelTraining and Validation Accuracy.Traing and alidaton Lossraning and Validation Lossraining and Validation LosFigure 7. Illustration of model accuracy rate for 50, 30, 20, and 10 epochs for DB4 dataset generatedas synthetic fingerprints.Inventions 2022, 7, 3911 of 13Table 4. The performance of the proposed model.Test Accuracy (%)Number of Test SamplesValidation Accuracy (%)DatabaseValidation LossPrewitt FilterLoG FilterBD114498.70.058669.875.61873.106162.570.2BD267.6BD318794.70.193171.673.4BD41870.034469.875.698.7The results in Figures - indicate that, while the accuracy and loss of the trainingdata have very good values, the accuracy and loss of the validation dataset is influenced bythe epoch number, indicating the existence of overfitting or underfitting. Our data indicatesthe overfitting of the model starting with the seventh epoch. In this case, it is necessaryto stop the model early by tuning the hyperparameter. The CNN performance is stronglyinfluenced by the quality of a fingerprint image and by its local and global structures. Theimages, which in our case show an important variability from dataset to dataset. Theperformance on the test data (20% of each dataset) is lower than the accuracy provided bythe training data, with the amendment that the number of samples is reduced for the testset. However, the LoG filter increased the accuracy compared to the Prewitt filter, and itis a better solution to enhance the edges in the fingerprint images. Additionally, the rawimages in the DB2 dataset that were acquired using the optical sensor "U.are.U 4000" had alow quality that affected the performance of the classification.According to the data in Table , the accuracy values determined in the training andvalidation sets are in line with the reported results in the literature. In f d, an accuracy of85% was reported for images belonging to the FVC2004 database which were processedusing a CNN-based automatic latent fingerprint matching system which uses the localI reported a 99.2% classification accuracy for theminutiae features. Mohamed et al. training set in an experiment which used the NIST DB4 dataset and 4000 fingerprint images.Militello et al. [together with the PolyU and NIST fingerprint databases.The accuracy values determined for the test set were slightly worse, thus indicatinga smaller drop in performance. However, we have mentioned that our proposed methodused the whole fingerprint images and the computation time is small compared to theother reported method. As an example, in [of 39 ms/image were reported for a pre-trained CNN architecture of the VGG-F networkIn addition, CNN architectures have some drawbacks, such as a poor generalizationcapacity, a requirement for a huge training dataset, and a low stability to geometricalovercome by increasing the training data size to allow the network to train on as many samples as possible. The obtained results indicate that the CNN performance is greatlyinfluenced by the guality of the fingerprint images. The low stability of the network is dueto the diversity of finger scanners which were used to acquire the fingerprints, such asoptical and thermal sweeping sensors, and synthetic fingerprints as well. Finding a solutionto provide a good performance of classification for this variety of data was a big challengefor our method. Our approach integrates the monitoring of training and validation by setting the number of epochs as a form of regularization, and learning curve graphs todecide on the model convergence.4. ConclusionsThe work conducted in this paper is mainly devoted to fingerprint identificationusing a CNN network that can perform fingerprint classification by considering wholeInventions 2022, 7, 3912 of 13fingerprint images. The proposed algorithm uses poor-quality original raw fingerprintimages. These were processed using Prewitt and Laplace filters to enhance the edges and,in order to reduce the expensive training cost, data resizing was applied. Hyper-parameterclassification. Our results indicate the overfitting of the model starting with the seventhepoch. The classification accuracy varied from 67.6% to 98.7% for the validation set, andfrom 70.2% to 75.6% for the test set. Following these considerations, we would argue thatthe proposed method can achieve a very good performance compared to the traditionalhand-crafted features method, despite the fact that it uses raw data and does not performany handcrafted feature extraction operationsFor future developments, we are interested in improving the performance of classifi-tuning. Additionally, other fingerprint databases will be used to assess the generalizationcapabilities of CNN architectures.A.-M.D.L. and L.M.; validation, S.M. and A.-M.D.L.; formal analysis, A.-M.D.L.; investigation, S.M. andInstitutional Review Board Statement: Not applicable.Data Availability Statement: Not applicable.Acknowledgments: The authors thank the anonymous referees whose comments helped to improvethe paperConflicts of Interest: The authors declare no conflict of interestReferencesJain, A.K. An Introduction to Biometric Recognition. IEEE Trans. Circuits Syst. Video Technol. 2004, 14, 4-20. [Maltoni, D.; Maio, M.; Jain, A.K.; Prabhakar, S. Fingerprint analysis and representation. In Handbook of Fingerprint Recognition;Springer Professional Computing; Springer: New York, NY, USA, 2003; pp. 83-130Deshpande, U.U.; Malemath, VS.; Patil Shivanand, M.; Chaugule Sushma, V. A Convolution Neural Network-based LatentFingerprint Matching using the combination of Nearest Neighbor Arrangement Indexing. Front. Robot. AI 2020, 7, 113. [Militello, C.; Conti, V.; Sorbello, F.; Vitabile, S. A novel embedded fingerprints authentication system based on singularity points.Technical University of Catalonia, IEEE Computer Society, Barcelona, Spain, 4-7 March 2008; Pp. 72-78.Conti, V.; Militello, C.; Sorbello, F.; Vitabile, S. Introducing pseudo-singularity points for efficient fingerprints classification(CISIS-2010), Krakow, Poland, 15-18 February 2010; pp. 368-375.Saponara, S.; Elhanashi, A.; Zheng, Q. Recreating Fingerprint Images by Convolutional Neural Network Autoencoder ArchitectureIEEE Access 2021, 9, 147888-147899. [invariant minutiae features. Int. J. Inf. Tecnol. 2022, 14, 1025-1039. [Wang, T.; Zheng, Z.; Bashir, A.K.; Jolfaei, A.; Xu, Y. FinPrivacy. A privacy-preserving mechanism for fingerprint identification.ACM Trans. Int. Technol. 2021, 21, 56. [Dhar, R.; Gupta, R.; Baishnab, K.L. An analysis of Canny and Laplacian of (Gaussian image filtersretinal image. In Proceedings of the International Conference on Green Computing Communication and Electrical Engineering(ICGCCEE), Coimbatore, India, 6-8 March 2014.10.2017, 5, 695-704.Szegedy, C.; Ioffe, S.; Vanhoucke, V.; Alemi, A. Inception-v4, Inception-Resnet and the impact of residual connections on learning.11.In Proceedings of the AAAI Conference on Artificial Intelligence, San Francisco, CA, USA, 4-9 February 2017.Inventions 2022, 7, 3913 of 1312. Zhu, Y.; Yin, X.; Jia, X.; Hu, J. Latent fingerprint segmentation based on convolutional neural networks. In Proceedings of theIEEE Workshop on Information Forensics and Security, Rennes, France, 4-7 December 2017; pp. 1-6.13.Shrein, J.M. Fingerprint classification using convolutional neural networks and ridge orientation images. In Proceedings of theIEEE Symposium Series on Computational Intelligence (SSCI), Honolulu, HI, USA, 7 November-1 December 2017.Mohamed, M.H. Fingerprint Classification Using Deep Convolutional Neural Network. J. Electr. Electron. Eng. 2021, 9, 147-15214.Militello, C.; Rundo, L.; Vitabile, S.; Conti, V. Fingerprint Classification Based on Deep Learning Approaches: Experimental15.Findings and Comparisons. Symmetry 2021, 13, 750. [Wang, J.-W.; Tuyen Le, N.; Wang, C.-C.; Lee, J.-S. Enhanced ridge structure for improving fingerprint image quality based on a16.wavelet domain. IEEE Signal Process. Lett. 2015, 22, 390-394. [Yang, J.; Xiong, N.; Vasilakos, A.V. Two-stage enhancement scheme for low-quality fingerprint images by learning from the17.images. IEEE Trans. Hum. Mach. Syst. 2013, 43, 235-248. [18.operation and AGNN classifier. Appl. Comput. Inform. 2018, 14, 166-176..9.Tertychnyi, P.; Ozcinar, C.; Anbarjafari, G. Low-quality fingerprint classification using deep neural network. IET Biom. 2018, 7,20.550-556.[21.Pandya, B.; Cosma, G.; Alani, A.A.; Taherkhani, A.; Bharadi, V.; McGinnity, T.M. Fingerprint classification using a deepconvolutional neural network. In Proceedings of the 2018 4th International Conference on Information Management, Oxford, UK25-27 May 2018.22.by Gabor filter and deep learning. Comput. Electr. Eng. 2021, 95, 107387. [Trabelsi, S.; Samai, D.; Dornaika, F.; Benlamoudi, A.; Bensid, K.; Taleb-Ahmed, A. Efficient palmprint biometric identification23.systems using deep learning and feature selection methods. Neural Comput. Appl. 2022, 1-23. [Oleiwi, B.K.; Abood, L.H.; Farhan, A.K. Integrated different fingerprint identification and classification systems based deep24.Iraq, 15-17 March 2022; pp. 188-193.Kumar, S.; Singh, M.; Shaw, D.K. Comparative Analysis of Various Edge Detection Techniques in Biometric. Int. J. Eng. Technol.25.2016, 8, 2452-2459. [26.Unio. Galati Math. Phys. Theor. Mech. 2017, 1, 51-57.Sun, Q.; Hou, Y; Tan, Q.; Li, C.; Liu, M. A robust edge detection method with sub-pixel accuracy. Optik JLEO 2014, 125, 3449-345327.Baareh, A.; Al-Jarrah, A.; Smadi, A.; Shakah, G. Performance Evaluation of Edge Detection Using Sobel, Homogeneity and28.Prewitt Algorithms. J. Softw. Eng. Appl. 2018, 11, 537-551.Cui, S.; Wang, Y.; Qian, X.; Deng, Z. Image Processing Techniques in Shockwave Detection and Modeling. J. Signal Inf. Process29.2013, 4, 109-113. [30.Unio. Galati Math. Phys. Theor. Mech. 2019, 1, 34-42. [FVC2004: Third Fingerprint Verification Competition. Available online:31.(accessedon 10 February 2022)Canziani, A.; Paszke, A.; Culurciello, E. An analysis of deep neural network models for practical applications. arXio 201632.33Ann. Dunarea Jos Unio. of Galati Math. Phys. Theor. Mech. 2021, 1, 53-62. [Michelsanti, D.; Ene, A.; Guichi, Y; Stef, R.; Nasrollahi, K.; Moeslund, T.B. Fast fingerprint classification with deep neuralnetworks. In Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory anaApplications, VISAPP, Porto, Portugal, 27 February-1 March 2017; Scitepress: Setubal, Portugal, 2017; Volume 5, Pp. 202-209.